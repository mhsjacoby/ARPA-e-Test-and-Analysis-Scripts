{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadWriteData():\n",
    "    def __init__(self, path1, name):\n",
    "        self.root_directory = os.path.join(path1, name, 'env_params')\n",
    "        self.root_dir = path1\n",
    "        self.name = name\n",
    "        self.home = self.root_dir.split('/')[-1].split('-')[-1]\n",
    "        self.data = {}\n",
    "        self.all_dfs = {}\n",
    "        self.first_last = {}\n",
    "    \n",
    "        \n",
    "    def csv_name(self, day):       \n",
    "        return str(self.home + '_' + self.name + '_' + day + '.csv')  \n",
    "\n",
    "    def mylistdir(self, directory):\n",
    "        filelist = os.listdir(directory)\n",
    "        return [x for x in filelist if not (x.startswith('.') or 'Icon' in x)]           \n",
    "    \n",
    "    \n",
    "    def make_storage_directory(self, root):\n",
    "        target_dir = os.path.join(root, 'csv')\n",
    "        if os.path.exists(target_dir):\n",
    "            return target_dir\n",
    "        else:\n",
    "            os.mkdir(target_dir)\n",
    "            return target_dir\n",
    "\n",
    "        \n",
    "    def read_in_data(self, path, day):\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                self.data_dicts = json.loads(f.read())\n",
    "                for time_point in self.data_dicts:\n",
    "                    for measure in time_point:\n",
    "                        self.measurements[measure].append(time_point[measure])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    def get_date_folders(self, path):\n",
    "        date_folders = self.mylistdir(path)\n",
    "        date_folders.sort()\n",
    "        self.day1, self.dayn = date_folders[0], date_folders[-1]\n",
    "        return date_folders\n",
    "    \n",
    "    \n",
    "    def get_all_data(self, path, day):\n",
    "        self.measurements = {\n",
    "            'time':[], 'tvoc_ppb':[], 'temp_c':[], 'rh_percent':[], \n",
    "            'light_lux':[],'co2eq_ppm':[], 'dist_mm':[], 'co2eq_base':[], 'tvoc_base':[]}\n",
    "        file_path = os.path.join(path, day)\n",
    "        minute_folders = self.mylistdir(file_path)\n",
    "        minute_folders.sort()\n",
    "        min_1, min_L = minute_folders[0], minute_folders[-1]\n",
    "        min_n = str(int(min_L) + 4).zfill(4)\n",
    "        self.first_last[day] = min_1, min_n\n",
    "        for minute in minute_folders:\n",
    "            sub_files_path = os.path.join(file_path, minute)\n",
    "            sub_files = self.mylistdir(sub_files_path)\n",
    "            for file in sub_files:\n",
    "                if file.endswith('.json') == True:\n",
    "                    self.read_in_data(os.path.join(sub_files_path, file), day)\n",
    "        self.data[day] = self.measurements\n",
    "            \n",
    "            \n",
    "    def make_date_range(self, day1, dayn = None, t1 = '0000', tn = '2359'):\n",
    "        self.range_start = str(day1 + ' ' + t1[0:2] + ':' + t1[2:4] + ':00')\n",
    "        self.range_end = str(day1 + ' ' + tn[0:2] + ':' + tn[2:4] + ':50')\n",
    "        date_range = pd.date_range(start=self.range_start, end=self.range_end, freq='10s')\n",
    "        return date_range              \n",
    "            \n",
    "    def create_full_dfs(self, df, day):\n",
    "        #df2 = df.loc[df['date'] == f]         \n",
    "        day_start, day_end = self.first_last[day][0], self.first_last[day][1]\n",
    "        df_inner = self.make_date_range(day, t1 = day_start, tn = day_end)      \n",
    "        #df_fullday = self.make_date_range(day1 = day, dayn = day) ##use this for full 24hours\n",
    "        df2 = df.reindex(df_inner, fill_value = '')\n",
    "        return df2 \n",
    "                   \n",
    "    \n",
    "    def clean_dates(self, df, day):  \n",
    "        df['time'] = df['time'].str.strip('Z').str.replace('T',' ')\n",
    "        df['datetime_index'] = pd.to_datetime(df['time'])         \n",
    "        df = df.set_index('datetime_index')\n",
    "        df.index = df.index.floor('10s')\n",
    "        df2 = self.create_full_dfs(df, day)\n",
    "        \n",
    "        str_date = df2.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        df2.insert(loc = 0, column = 'str_datetime', value = str_date)\n",
    "        datetime_col = df2['str_datetime'].str.split(' ', n = 1, expand = True)         \n",
    "        df2.insert(loc = 0, column = 'date', value = datetime_col[0])        \n",
    "        time_col = datetime_col[1].str.split(':', n = 2, expand = True)    \n",
    "        df2.insert(loc = 0, column = 'second', value = time_col[2])\n",
    "        df2.insert(loc = 0, column = 'minute', value = time_col[1])\n",
    "        df2.insert(loc = 0, column = 'hour', value = time_col[0])        \n",
    "        df2 = df2.drop(columns = ['str_datetime', 'time'])\n",
    "        df2 = df2.sort_values(by = ['date', 'hour', 'minute', 'second'])\n",
    "        df2['home'] = self.home\n",
    "        df2['sensor'] = self.name\n",
    "        return df2   \n",
    " \n",
    "    \n",
    "    def get_ground_truth(self):\n",
    "        ground_path = os.path.join(self.root_dir, 'GroundTruth')\n",
    "        occupant_files = self.mylistdir(ground_path)\n",
    "        occupants = {}\n",
    "        for occ in occupant_files:\n",
    "            occupant_name = occ.split('-')[0]\n",
    "            ishome = []\n",
    "            with open(os.path.join(ground_path, occ)) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                for row in csv_reader:\n",
    "                    if occupant_name == 'Maggie':\n",
    "                        status, when = row[1], row[2].split('2019')\n",
    "                        d = when[0].strip('th, st, nd, rd, ')\n",
    "                        dt_day = datetime.strptime(str(d + ' 2019' + when[1]), '%b %d %Y %I:%M %p')\n",
    "                    else:                                     \n",
    "                        status, when = row[1], row[2].split('at')\n",
    "                        dt_day = datetime.strptime(str(when[0] + when[1]), '%B %d, %Y  %I:%M%p')\n",
    "                    ishome.append((status, dt_day))\n",
    "            occupants[occupant_name] = ishome\n",
    "        return occupants\n",
    "    \n",
    "        \n",
    "    def attach_ground_truth(self, df, occupants):\n",
    "        for occ in occupants:\n",
    "            df[occ] = 99\n",
    "            s1 = 'entered'\n",
    "            for r in occupants[occ]:\n",
    "                date = r[1]\n",
    "                s2 = r[0]\n",
    "                df.loc[(df.index < date) & (df[occ]==99) & (s1 == 'entered') & (s2 == 'exited'), occ] =  1\n",
    "                df.loc[(df.index < date) & (df[occ]==99) & (s1 == 'exited') & (s2 == 'entered'), occ] =  0\n",
    "                s1 = s2\n",
    "        df['number'] = df[list(occupants.keys())].sum(axis = 1)\n",
    "        df['occupied'] = 0\n",
    "        df.loc[df['number'] > 0, 'occupied'] = 1\n",
    "        return(df)        \n",
    "        \n",
    "      \n",
    "\n",
    "    def write_data(self, all_dfs, folders):\n",
    "        storage_path = self.make_storage_directory(self.root_dir)\n",
    "        for f in folders:\n",
    "            target_fname = os.path.join(storage_path, self.csv_name(f)) \n",
    "            df_to_write = all_dfs[f]\n",
    "            if os.path.isfile(target_fname) is False:\n",
    "                df_to_write.to_csv(target_fname, index = True)\n",
    "                print(target_fname + ': Write Sucessful!')\n",
    "            else:\n",
    "                print(target_fname + ': File already exists')\n",
    "\n",
    "                   \n",
    "                    \n",
    "    def main(self):        \n",
    "        date_folders = self.get_date_folders(self.root_directory)\n",
    "        occupancy = self.get_ground_truth()\n",
    "                \n",
    "        for day in date_folders:\n",
    "            self.get_all_data(self.root_directory, day)\n",
    "            new_df = pd.DataFrame.from_dict(self.data[day])\n",
    "            cleaned_data = self.clean_dates(new_df, day)\n",
    "            dfwTruth = self.attach_ground_truth(cleaned_data, occupancy)\n",
    "            self.all_dfs[day] = dfwTruth\n",
    "        \n",
    "        #self.write_data(self.all_dfs, date_folders)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "root_path = '/Users/maggie/Desktop/HPD_mobile-H1'\n",
    "sensors = ['BS1', 'BS2', 'BS3', 'BS4', 'BS5', 'BS6']\n",
    "#sensors = ['BS2', 'BS3']\n",
    "#sensors_red = ['RS1', 'RS2', 'RS3', 'RS4', 'RS5']\n",
    "\n",
    "\n",
    "all_dfs = {}\n",
    "first_last = {}\n",
    "\n",
    "for sensor in sensors:\n",
    "    P = ReadWriteData(root_path, sensor)\n",
    "    P.main()\n",
    "    all_dfs[sensor] = P.all_dfs\n",
    "    #print(sensor)\n",
    "    #for day in P.first_last.keys():\n",
    "        #print(sensor, day, P.first_last[day], len(P.all_dfs[day]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 2359\n",
      "<class 'str'> <class 'datetime.datetime'>\n",
      "2019-02-11 23:59:40 2019-02-11 23:59:40\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/maggie/Desktop/HPD_mobile-H1'\n",
    "sensors = ['BS1']\n",
    "server_id = sensors[0]\n",
    "audio_tape_length = '20'\n",
    "root_dir = os.path.join(path, server_id, 'audio')\n",
    "\n",
    "def mylistdir(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    return [x for x in filelist if not (x.startswith('.') or 'Icon' in x)] \n",
    "\n",
    "def get_date_folders(path):\n",
    "    date_folders = mylistdir(path)\n",
    "    date_folders.sort()\n",
    "\n",
    "    #print(date_folders)\n",
    "    return date_folders \n",
    "\n",
    "\n",
    "folders = get_date_folders(root_dir)\n",
    "day1, dayn = folders[0], folders[-1]\n",
    "\n",
    "#all_days = pd.date_range(start = day1, end = dayn, freq = 'D').tolist()\n",
    "DAYS = [str(day.date()) for day in pd.date_range(start = day1, end = dayn, freq = 'D').tolist()]\n",
    "#print(DAYS)\n",
    "\n",
    "missing_days = [day for day in DAYS if day not in folders]\n",
    "#print(missing_days)\n",
    "\n",
    "\n",
    "# for day in all_days:\n",
    "#     da = str(day.date())\n",
    "\n",
    "#     if da in folders:\n",
    "#         print(da, 'in folder')\n",
    "#     else:\n",
    "#         print(da, 'not in folder')\n",
    "# d = missing_days[0]\n",
    "# hr_min = '2305'\n",
    "\n",
    "# a = datetime.strptime((d + ' ' + hr_min), '%Y-%m-%d %H%M')\n",
    "# print(a)\n",
    "\n",
    "\n",
    "def mylistdir(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    return [x for x in filelist if not (x.startswith('.') or 'Icon' in x)] \n",
    "\n",
    "# print(DAYS)\n",
    "# for d in DAYS:\n",
    "#     #print(d)\n",
    "    \n",
    "#     hr_min_dirs = mylistdir(os.path.join(root_dir, d))\n",
    "#     #print(hr_min_dirs)\n",
    "\n",
    "#     for hr_min in hr_min_dirs:\n",
    "#         #print(hr_min)\n",
    "#         #print(d + ' ' + hr_min)\n",
    "#         a = datetime.strptime((d + ' ' + hr_min), '%Y-%m-%d %H%M')\n",
    "#         #print(a)\n",
    "\n",
    "#         temp = os.path.join(root_dir, d, hr_min)\n",
    "#         #print(temp)\n",
    "\n",
    "        \n",
    "        \n",
    "end_sec = str(60-int(audio_tape_length))     \n",
    "\n",
    "day = DAYS[1]\n",
    "#print(day)\n",
    "\n",
    "date_path = os.path.join(root_dir, day)\n",
    "hr_mins = mylistdir(date_path)\n",
    "hr_mins.sort()\n",
    "min_i, min_f = hr_mins[0], hr_mins[-1]\n",
    "print(min_i, min_f)\n",
    "\n",
    "b_dt = str(day + ' ' + min_i[0:2] + ':' + min_i[2:4] + ':00')\n",
    "# e_dt = str(day + ' ' + min_f[0:2] + ':' + min_f[2:4] + ':' + end_sec)\n",
    "\n",
    "b2 = datetime.strptime((day + ' ' + min_i), '%Y-%m-%d %H%M')\n",
    "e2 = datetime.strptime((day + ' ' + min_f + end_sec), '%Y-%m-%d %H%M%S')\n",
    "b_f = str(day + ' 00:00:00')\n",
    "e_f = str(day + ' 23:59:' + end_sec)\n",
    "\n",
    "print(type(b_dt), type(b2))\n",
    "print(e_dt, e2)\n",
    "\n",
    "all_mins_within = pd.date_range(b_dt, e_dt, freq = audio_tape_length+'S').tolist()\n",
    "all_day = pd.date_range(b_f, e_f, freq = audio_tape_length+'S').tolist()\n",
    "\n",
    "all_minutes = pd.date_range(b_dt, e_dt, freq = '60S').tolist()\n",
    "#print(all_minutes)\n",
    "#print(len(all_minutes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 2019-02-10 BS1\n",
      "Start Time :  22:29\n",
      "End Time :  23:58\n",
      "Expected number of wavs :  270\n",
      "Number of unique wavs :  206\n",
      "Total number of duplicates :  0\n",
      "Number of not captured wavs :  64\n",
      "Percent of wavs captured :  0.76\n",
      "Expected number of directories :  90\n",
      "Number of directories w/ correct number wavs :  62\n",
      "Number of directories w/ incorrect number wavs :  10\n",
      "Number of directories w/ zero wavs :  18\n",
      "Directories per hour w/ zero wavs :  {'22:00': 3, '23:00': 15}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-11 BS1\n",
      "Start Time :  00:00\n",
      "End Time :  23:59\n",
      "Expected number of wavs :  4320\n",
      "Number of unique wavs :  14\n",
      "Total number of duplicates :  0\n",
      "Number of not captured wavs :  4306\n",
      "Percent of wavs captured :  0.0\n",
      "Expected number of directories :  1440\n",
      "Number of directories w/ correct number wavs :  4\n",
      "Number of directories w/ incorrect number wavs :  1\n",
      "Number of directories w/ zero wavs :  329\n",
      "Directories per hour w/ zero wavs :  {'00:00': 54, '01:00': 44, '02:00': 34, '03:00': 15, '04:00': 24, '05:00': 14, '06:00': 19, '07:00': 9, '08:00': 12, '09:00': 4, '10:00': 5, '11:00': 8, '12:00': 3, '13:00': 7, '14:00': 5, '15:00': 11, '16:00': 6, '17:00': 8, '18:00': 9, '19:00': 10, '20:00': 3, '23:00': 25}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-12 BS1\n",
      "Start Time :  00:00\n",
      "End Time :  23:59\n",
      "Expected number of wavs :  4320\n",
      "Number of unique wavs :  4068\n",
      "Total number of duplicates :  0\n",
      "Number of not captured wavs :  252\n",
      "Percent of wavs captured :  0.94\n",
      "Expected number of directories :  1440\n",
      "Number of directories w/ correct number wavs :  1246\n",
      "Number of directories w/ incorrect number wavs :  158\n",
      "Number of directories w/ zero wavs :  31\n",
      "Directories per hour w/ zero wavs :  {'00:00': 19, '01:00': 1, '02:00': 1, '04:00': 1, '05:00': 1, '09:00': 1, '13:00': 1, '14:00': 1, '16:00': 2, '17:00': 1, '19:00': 1, '23:00': 1}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-13 BS1\n",
      "Start Time :  00:00\n",
      "End Time :  23:59\n",
      "Expected number of wavs :  4320\n",
      "Number of unique wavs :  3200\n",
      "Total number of duplicates :  3\n",
      "Number of not captured wavs :  1120\n",
      "Percent of wavs captured :  0.74\n",
      "Expected number of directories :  1440\n",
      "Number of directories w/ correct number wavs :  980\n",
      "Number of directories w/ incorrect number wavs :  135\n",
      "Number of directories w/ zero wavs :  261\n",
      "Directories per hour w/ zero wavs :  {'02:00': 2, '03:00': 1, '06:00': 2, '10:00': 11, '11:00': 60, '12:00': 60, '13:00': 60, '14:00': 58, '16:00': 1, '18:00': 1, '19:00': 1, '20:00': 2, '22:00': 2}\n",
      "Hours with no wavs :  ['11:00', '12:00', '13:00']\n",
      "\n",
      "\n",
      " 2019-02-14 BS1\n",
      "Start Time :  00:17\n",
      "End Time :  23:58\n",
      "Expected number of wavs :  4266\n",
      "Number of unique wavs :  4109\n",
      "Total number of duplicates :  0\n",
      "Number of not captured wavs :  157\n",
      "Percent of wavs captured :  0.96\n",
      "Expected number of directories :  1422\n",
      "Number of directories w/ correct number wavs :  1284\n",
      "Number of directories w/ incorrect number wavs :  128\n",
      "Number of directories w/ zero wavs :  10\n",
      "Directories per hour w/ zero wavs :  {'00:00': 1, '01:00': 1, '03:00': 1, '04:00': 1, '09:00': 1, '11:00': 2, '15:00': 1, '16:00': 1, '17:00': 1}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-15 BS1\n",
      "Start Time :  00:00\n",
      "End Time :  23:59\n",
      "Expected number of wavs :  4320\n",
      "Number of unique wavs :  4183\n",
      "Total number of duplicates :  3\n",
      "Number of not captured wavs :  137\n",
      "Percent of wavs captured :  0.97\n",
      "Expected number of directories :  1440\n",
      "Number of directories w/ correct number wavs :  1325\n",
      "Number of directories w/ incorrect number wavs :  107\n",
      "Number of directories w/ zero wavs :  8\n",
      "Directories per hour w/ zero wavs :  {'00:00': 2, '04:00': 1, '09:00': 1, '14:00': 1, '15:00': 1, '18:00': 1, '19:00': 1}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-16 BS1\n",
      "Start Time :  00:00\n",
      "End Time :  23:59\n",
      "Expected number of wavs :  4320\n",
      "Number of unique wavs :  4133\n",
      "Total number of duplicates :  3\n",
      "Number of not captured wavs :  187\n",
      "Percent of wavs captured :  0.96\n",
      "Expected number of directories :  1440\n",
      "Number of directories w/ correct number wavs :  1298\n",
      "Number of directories w/ incorrect number wavs :  126\n",
      "Number of directories w/ zero wavs :  16\n",
      "Directories per hour w/ zero wavs :  {'03:00': 1, '04:00': 2, '07:00': 1, '08:00': 1, '11:00': 3, '12:00': 1, '13:00': 1, '14:00': 1, '15:00': 3, '16:00': 1, '17:00': 1}\n",
      "Hours with no wavs :  []\n",
      "\n",
      "\n",
      " 2019-02-18 BS1\n",
      "Start Time :  17:17\n",
      "End Time :  23:57\n",
      "Expected number of wavs :  1203\n",
      "Number of unique wavs :  1156\n",
      "Total number of duplicates :  0\n",
      "Number of not captured wavs :  47\n",
      "Percent of wavs captured :  0.96\n",
      "Expected number of directories :  401\n",
      "Number of directories w/ correct number wavs :  360\n",
      "Number of directories w/ incorrect number wavs :  38\n",
      "Number of directories w/ zero wavs :  3\n",
      "Directories per hour w/ zero wavs :  {'17:00': 2, '21:00': 1}\n",
      "Hours with no wavs :  []\n"
     ]
    }
   ],
   "source": [
    "#path = '/Users/maggie/Desktop/HPD_mobile-H1'\n",
    "path = '/Users/maggie/Desktop/HPD_mobile-H1'\n",
    "\n",
    "sensors = ['BS1']\n",
    "server_id = sensors[0]\n",
    "audio_tape_length = '20'\n",
    "root_dir = os.path.join(path, server_id, 'audio')\n",
    "#print(path)\n",
    "\n",
    "a = AudioChecker(path, server_id, audio_tape_length)\n",
    "a.main()\n",
    "#print(len(a.count_correct))\n",
    "#t = a.configure_output()['Directories w/ zero wavs'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioChecker():\n",
    "    def __init__(self, path, server_id, tape_length, display_output = True, write_file = False):\n",
    "        self.write_file = write_file        \n",
    "        self.display_output = display_output \n",
    "        self.root_dir = os.path.join(path, server_id, 'audio')\n",
    "        self.server_id = server_id\n",
    "        self.audio_tape_length = tape_length\n",
    "        self.correct_files_per_dir = int(60/int(self.audio_tape_length))        \n",
    "        self.date_folders = self.get_date_folders(self.root_dir)\n",
    "        self.date_dirs = [str(day.date()) for day in pd.date_range(start = self.day1, end = self.dayn, freq = 'D').tolist()]\n",
    "        self.missing_days = [day for day in self.date_dirs if day not in self.date_folders]        \n",
    "        self.day_summary = {}\n",
    "        self.count_correct = {}\n",
    "        self.wavs = []\n",
    "        self.first_last = {}\n",
    "        self.end_sec = str(60-int(self.audio_tape_length))\n",
    "\n",
    "        \n",
    "    def mylistdir(self, directory):\n",
    "        filelist = os.listdir(directory)\n",
    "        return [x for x in filelist if not (x.startswith('.') or 'Icon' in x)] \n",
    "    \n",
    "    def get_date_folders(self, path):\n",
    "        date_folders = self.mylistdir(path)\n",
    "        date_folders.sort()\n",
    "        self.day1, self.dayn = date_folders[0], date_folders[-1]\n",
    "        return date_folders   \n",
    "                   \n",
    "            \n",
    "    def get_all_mins(self, day, hr_mins):\n",
    "        date_path = os.path.join(self.root_dir, day)\n",
    "        hr_mins.sort()\n",
    "        min_i, min_f = hr_mins[0], hr_mins[-1]\n",
    "        self.first_last = min_i, min_f\n",
    "        b_f = str(day + ' 00:00:00')\n",
    "        e_f = str(day + ' 23:59:' + self.end_sec)        \n",
    "        b_dt = datetime.strptime((day + ' ' + min_i), '%Y-%m-%d %H%M')\n",
    "        e_dt = datetime.strptime((day + ' ' + min_f + self.end_sec), '%Y-%m-%d %H%M%S')        \n",
    "        self.expected_wavs = pd.date_range(b_dt, e_dt, freq = self.audio_tape_length + 'S').tolist()\n",
    "        self.all_seconds = pd.date_range(b_f, e_f, freq = self.audio_tape_length + 'S').tolist()\n",
    "        self.expected_dirs = pd.date_range(b_dt, e_dt, freq = '60S').tolist()\n",
    "        self.all_minutes = pd.date_range(b_f, e_f, freq = '60S').tolist()\n",
    "        \n",
    "\n",
    "    def finder(self):\n",
    "        for wav in self.wavs:\n",
    "            dt = datetime.strptime(wav.split('_')[0], '%Y-%m-%d %H%M%S')\n",
    "            try:\n",
    "                ind = self.expected_wavs.index(dt)\n",
    "                self.expected_wavs.pop(ind)\n",
    "            except:\n",
    "                self.duplicates += 1\n",
    "                self.duplicates_ts.append(dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                pass\n",
    "\n",
    "    def writer(self, output_dict):\n",
    "        if self.write_file:\n",
    "\n",
    "            b = 'test_output.json'\n",
    "            write_file = os.path.join(self.root_dir, b)\n",
    "            print('Writing file to: {}'.format(write_file))\n",
    "            with open(write_file, 'w+') as f:\n",
    "                f.write(json.dumps(output_dict))\n",
    "    \n",
    "    def displayer(self, output_dict, d):\n",
    "        if self.display_output:\n",
    "            for key in output_dict:\n",
    "                print(key, ': ', output_dict[key])\n",
    "        else:\n",
    "            print('No output')\n",
    "\n",
    "    def configure_output(self,d):\n",
    "        if self.write_file or self.display_output:\n",
    "            missed_seconds = []\n",
    "\n",
    "            for ts in self.expected_wavs:\n",
    "                missed_seconds.append(ts.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            \n",
    "            unique_wavs = self.total_wavs - self.duplicates\n",
    "            perc = unique_wavs / self.expect_num_wavs\n",
    "            self.perc_cap = float(\"{0:.2f}\".format(perc))\n",
    "            self.zero_hours = [hr for hr in self.zero_dirs if self.zero_dirs[hr] == 60]\n",
    "                            \n",
    "            output_dict = {\n",
    "#                 'Sensor': self.server_id,\n",
    "#                 'Date': d,\n",
    "                'Start Time': datetime.strptime(self.first_last[0], '%H%M').strftime('%H:%M'),\n",
    "                'End Time': datetime.strptime(self.first_last[1], '%H%M').strftime('%H:%M'),\n",
    "                'Expected number of wavs': self.expect_num_wavs,\n",
    "                'Number of unique wavs': unique_wavs,\n",
    "                'Total number of duplicates': self.duplicates,\n",
    "                'Number of not captured wavs': len(self.expected_wavs),\n",
    "                'Percent of wavs captured': self.perc_cap,\n",
    "                #'Number of missed wavs': len(missed_seconds),\n",
    "                'Expected number of directories': len(self.expected_dirs),\n",
    "                'Number of directories w/ correct number wavs': len(self.count_correct),\n",
    "                'Number of directories w/ incorrect number wavs': len(self.count_other),\n",
    "                'Number of directories w/ zero wavs': len(self.num_zero_dirs),\n",
    "                'Directories per hour w/ zero wavs': self.zero_dirs,\n",
    "                'Hours with no wavs': self.zero_hours\n",
    "                #'Timestamps of not captured wavs': missed_seconds,\n",
    "            }\n",
    "        return output_dict\n",
    "   \n",
    "    \n",
    "    def main(self):\n",
    "        for d in self.date_folders:\n",
    "            hr_min_dirs = mylistdir(os.path.join(self.root_dir, d))\n",
    "            self.get_all_mins(d, hr_min_dirs)\n",
    "            self.expect_num_wavs = len(self.expected_wavs)\n",
    "            self.expect_num_directories = len(self.expected_dirs)\n",
    "            self.count_correct = {}\n",
    "            self.zero_dirs = {}\n",
    "            self.num_zero_dirs = []\n",
    "            self.zero_hours = []\n",
    "            \n",
    "            self.count_other = {}\n",
    "            self.duplicates = 0\n",
    "            self.duplicates_ts = [] \n",
    "            \n",
    "            self.total_wavs = 0            \n",
    "            for hr_min in hr_min_dirs:\n",
    "                a = datetime.strptime((d + ' ' + hr_min), '%Y-%m-%d %H%M')\n",
    "                temp = os.path.join(self.root_dir, d, hr_min)\n",
    "                if os.path.isdir(temp):\n",
    "                    self.wavs = mylistdir(os.path.join(self.root_dir, d, hr_min))\n",
    "                    self.wavs = [x for x in self.wavs if x.endswith('.wav')]\n",
    "                    self.finder()\n",
    "                    self.total_wavs += len(self.wavs)\n",
    "                    \n",
    "                    hr = datetime.strptime(hr_min,'%H%M').strftime('%H:00')\n",
    "                    if len(self.wavs) == self.correct_files_per_dir:\n",
    "                        self.count_correct[hr_min] = self.correct_files_per_dir\n",
    "                    elif len(self.wavs) == 0:\n",
    "                        self.num_zero_dirs.append(hr_min)\n",
    "                        if hr not in self.zero_dirs:\n",
    "                            self.zero_dirs[hr] = 1\n",
    "                        else:\n",
    "                            self.zero_dirs[hr] += 1\n",
    "                    else:\n",
    "                        self.count_other[hr_min] = len(self.wavs)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            output_dict = self.configure_output(d)\n",
    "            self.day_summary[d] = output_dict\n",
    "            print('\\n\\n',d, self.server_id)\n",
    "            self.displayer(output_dict, d)\n",
    "        #self.writer(output_dict)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioChecker():\n",
    "    def __init__(self, path_to_import_conf, write_file, display_output, server_id):\n",
    "        # self.conf_file_path = path_to_import_conf\n",
    "        # self.import_conf(self.conf_file_path)\n",
    "        # self.write_file = write_file\n",
    "        #self.display_output = display_output\n",
    "        self.audio_tape_length = self.conf_dict['audio_tape_length']\n",
    "        self.all_seconds = pd.date_range(self.b_dt, self.e_dt, freq = self.audio_tape_length).tolist()\n",
    "        self.expect_num_wavs = len(self.all_seconds)\n",
    "        self.expect_num_directories = len(pd.date_range(self.b_dt, self.e_dt, freq = self.conf_dict[\"dir_create_freq\"]).tolist())\n",
    "        self.root_dir = os.path.join(self.conf_dict['root'], server_id, 'audio')\n",
    "        self.date_dirs = self.conf_dict['date_dirs']\n",
    "        self.hrs_to_pass = self.conf_dict['hr_dirs_to_skip']\n",
    "        self.correct_files_per_dir = self.conf_dict['audio_files_per_dir']\n",
    "        self.count_correct = {}\n",
    "        self.count_other = {}\n",
    "        self.total_wavs = 0\n",
    "        self.duplicates = 0\n",
    "        self.counter_min = 50\n",
    "        self.duplicates_ts = []\n",
    "        self.wavs = []\n",
    "        self.server = server_id\n",
    "\n",
    "    \n",
    "    def displayer(self, output_dict):\n",
    "        if self.display_output:\n",
    "            print(output_dict)\n",
    "\n",
    "    def configure_output(self):\n",
    "        if self.write_file or self.display_output:\n",
    "            missed_seconds = []\n",
    "\n",
    "            for ts in self.all_seconds:\n",
    "                missed_seconds.append(ts.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "            unique_wavs = self.total_wavs - self.duplicates\n",
    "            total = unique_wavs + len(self.all_seconds)\n",
    "            diff = total - self.expect_num_wavs\n",
    "            perc = unique_wavs / self.expect_num_wavs\n",
    "            self.perc_cap = float(\"{0:.2f}\".format(perc))\n",
    "\n",
    "            output_dict = {\n",
    "                'Configuration dict': self.conf_dict,\n",
    "                'Expected number of wavs': self.expect_num_wavs,\n",
    "                'Number of wavs counted (including duplicates)': self.total_wavs,\n",
    "                'Total number of duplicates': self.duplicates,\n",
    "                'Number of not captured wavs': len(self.all_seconds),\n",
    "                'Number of unique wavs': unique_wavs,\n",
    "                'Percent of audio files captured': self.perc_cap,\n",
    "                #'Expected number of directories': self.expect_num_directories,\n",
    "                #'Number of directories w/correct num wavs': len(self.count_correct),\n",
    "                #'Number of directories w/incorrect num wavs': len(self.count_other),\n",
    "                #'Non-correct wavs directories': self.count_other,\n",
    "                #'Timestamps of not captured wavs': missed_seconds,\n",
    "                #'Duplicates': self.duplicates_ts\n",
    "            }\n",
    "        else:\n",
    "            output_dict = []\n",
    "        return output_dict\n",
    "\n",
    "    def main(self):\n",
    "        for d in self.date_dirs:\n",
    "            hr_min_dirs = os.listdir(os.path.join(self.root_dir, d))\n",
    "            for hr_min in hr_min_dirs:\n",
    "                if hr_min in self.hrs_to_pass:\n",
    "                    print('Not looking in : {}'.format(os.path.join(self.root_dir, d, hr_min)))\n",
    "                    continue\n",
    "                else:\n",
    "                    a = datetime.strptime((d + ' ' + hr_min), '%Y-%m-%d %H%M')\n",
    "                    if a < self.b_dt_as_dt or a > self.e_dt_as_dt:\n",
    "                        continue\n",
    "                    else:\n",
    "                        temp = os.path.join(self.root_dir, d, hr_min)\n",
    "                        if os.path.isdir(temp):\n",
    "                            self.wavs = os.listdir(os.path.join(self.root_dir, d, hr_min))\n",
    "                            self.wavs = [x for x in self.wavs if x.endswith('.wav')]\n",
    "                            self.finder()\n",
    "                            self.total_wavs += len(self.wavs)\n",
    "                            if self.total_wavs > self.counter_min:\n",
    "                                print('Counting wav: {}'.format(self.total_wavs))\n",
    "                                self.counter_min += 50\n",
    "\n",
    "                            if len(self.wavs) == self.correct_files_per_dir:\n",
    "                                self.count_correct[os.path.join(d,hr_min)] = self.correct_files_per_dir\n",
    "\n",
    "                            elif len(self.wavs) != 3:\n",
    "                                self.count_other[os.path.join(d,hr_min)] = len(self.wavs)\n",
    "\n",
    "                        else:\n",
    "                            print('{} is not a dir'.format(temp))\n",
    "        \n",
    "        output_dict = self.configure_output()\n",
    "        self.writer(output_dict)\n",
    "        #self.displayer(output_dict)\n",
    "        print('All done!')\n",
    "        print('Server ID: ' + str(self.server))\n",
    "        print('Percent of files captured: ' + str(self.perc_cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvChecker():\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoChecker():\n",
    "    def __init__(self, path_to_import_conf, write_file, display_output, server_id):\n",
    "        # self.conf_file_path = path_to_import_conf\n",
    "        # self.import_conf(self.conf_file_path)\n",
    "        # self.write_file = write_file\n",
    "        # self.display_output = display_output\n",
    "        self.all_seconds = pd.date_range(self.b_dt, self.e_dt, freq = self.conf_dict['img_freq']).tolist()\n",
    "        self.expect_num_photos = len(self.all_seconds)\n",
    "        self.expect_num_directories = len(pd.date_range(self.b_dt, self.e_dt, freq = self.conf_dict[\"dir_create_freq\"]).tolist())\n",
    "        self.root_dir = os.path.join(self.conf_dict['root'], server_id, 'img')\n",
    "        self.date_dirs = self.conf_dict['date_dirs']\n",
    "        self.hrs_to_pass = self.conf_dict['hr_dirs_to_skip']\n",
    "        self.count_61 = {}\n",
    "        self.count_60 = {}\n",
    "        self.count_other = {}\n",
    "        self.total_pics = 0\n",
    "        self.count_61_double_00 = 0\n",
    "        self.duplicates = 0\n",
    "        self.counter_min = 2000\n",
    "        self.duplicates_ts = []\n",
    "        self.pics = []\n",
    "        self.start_time = datetime.now()\n",
    "\n",
    "    def configure_output(self):\n",
    "        if self.write_file:\n",
    "            missed_seconds = []\n",
    "\n",
    "            for ts in self.all_seconds:\n",
    "                missed_seconds.append(ts.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            rt = datetime.now() - self.start_time\n",
    "            mins = rt.seconds / 60\n",
    "            output_dict = {\n",
    "                'Configuration dict': self.conf_dict,\n",
    "                'Total runtime in minutes': mins,\n",
    "                'Expected number of photos': self.expect_num_photos,\n",
    "                'Number of photos counted (including duplicates)': self.total_pics,\n",
    "                'Total number of duplicates': self.duplicates,\n",
    "                'Number of not captured photos': len(self.all_seconds),\n",
    "                'Expected number of directories': self.expect_num_directories,\n",
    "                'Number of directories w/60 photos': len(self.count_60),\n",
    "                'Number of directories w/61 photos': len(self.count_61),\n",
    "                'Number of directories w/61 photos and 2x 00 second photos': self.count_61_double_00,\n",
    "                'Number of directories w/not 60 OR 61 photos': len(self.count_other),\n",
    "                'Non-60 or 61 directories': self.count_other,\n",
    "                'Timestamps of not captured photos': missed_seconds,\n",
    "                'Duplicates': self.duplicates_ts\n",
    "            }\n",
    "        else:\n",
    "            output_dict = []\n",
    "        return output_dict\n",
    "\n",
    "    def main(self):\n",
    "        for d in self.date_dirs:\n",
    "            hr_min_dirs = os.listdir(os.path.join(self.root_dir, d))\n",
    "            for hr_min in hr_min_dirs:\n",
    "                if not hr_min == '.DS_Store' and not hr_min in self.hrs_to_pass:\n",
    "                    a = datetime.strptime((d + ' ' + hr_min), '%Y-%m-%d %H%M')\n",
    "                    if a < self.b_dt_as_dt or a > self.e_dt_as_dt:\n",
    "                        continue\n",
    "                    else:\n",
    "                        temp = os.path.join(self.root_dir, d, hr_min)\n",
    "                        if os.path.isdir(temp):\n",
    "                            self.pics = os.listdir(os.path.join(self.root_dir, d, hr_min))\n",
    "                            self.pics = [x for x in self.pics if x.endswith('.png')]\n",
    "                            self.finder()\n",
    "                            self.total_pics += len(self.pics)\n",
    "                            if self.total_pics > self.counter_min:\n",
    "                                print('Counting picture: {}'.format(self.total_pics))\n",
    "                                rt = datetime.now() - self.start_time\n",
    "                                mins = rt.seconds / 60\n",
    "                                print('Current runtime in mins: {}'.format(mins))\n",
    "                                self.counter_min += 2000\n",
    "                            if len(self.pics) == 61:\n",
    "                                double_00 = [x for x in self.pics if x.split('_')[0].endswith('00')]\n",
    "                                if len(double_00) == 2:\n",
    "                                    self.count_61_double_00 += 1\n",
    "                                self.count_61[os.path.join(d,hr_min)] = 61\n",
    "\n",
    "                            elif len(self.pics) == 60:\n",
    "                                self.count_60[os.path.join(d,hr_min)] = 60\n",
    "                            else:\n",
    "                                self.count_other[os.path.join(d,hr_min)] = len(self.pics)\n",
    "\n",
    "                        else:\n",
    "                            print('{} is not a dir'.format(temp))\n",
    "        \n",
    "        output_dict = self.configure_output()\n",
    "        self.writer(output_dict)\n",
    "        self.displayer(output_dict)\n",
    "        print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PlottingData():\n",
    "    def __init__(self, dfs, measures, limits, colors):\n",
    "        self.all_dfs = dfs\n",
    "        self.measures = measures\n",
    "        self.limits = limits\n",
    "        self.colors = colors\n",
    "            \n",
    "    def get_all(self):\n",
    "        for sensor in self.all_dfs:\n",
    "            print(sensor)\n",
    "            for m, measure in enumerate(self.measures):\n",
    "                if measure in self.limits:\n",
    "                    low, high = self.limits[measure][0], self.limits[measure][1]\n",
    "                for date in self.all_dfs[sensor]:\n",
    "                    df = self.all_dfs[sensor][date]\n",
    "                    df2 = df.loc[df['date'] == date, ['TIME', measure, 'time'] ]\n",
    "                    if measure in self.limits:\n",
    "                        df2.loc[df2[measure] < low, [measure]] = low\n",
    "                        df2.loc[df2[measure] > high, [measure]] = high\n",
    "                    \n",
    "                    fig, ax = plt.subplots(figsize = (8,5)) \n",
    "                    ax.plot(df2[measure], color = self.colors[m])\n",
    "                    ax.set_ylabel(measure)\n",
    "                    ax.set_xlabel(date + ' : ' + sensor)\n",
    "\n",
    "                    myFmt = mdates.DateFormatter('%H')\n",
    "                    ax.xaxis.set_major_formatter(myFmt) \n",
    "                    fig.autofmt_xdate()\n",
    "\n",
    "                    plt.show()\n",
    "                    \n",
    "               \n",
    "            \n",
    "    def main(self):\n",
    "        self.get_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggie/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-415c86d34254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlottingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasures_to_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8e3afa26f3b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8e3afa26f3b7>\u001b[0m in \u001b[0;36mget_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TIME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmeasure\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                         \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "measures_to_plot = ['tvoc_ppb','temp_c','rh_percent','light_lux','co2eq_ppm','dist_mm']\n",
    "#measures_to_plot = ['temp_c']\n",
    "max_min = {'temp_c': [20, 30], 'rh_percent': [0,40], 'tvoc_ppb':[0,2000], 'co2eq_ppm':[0,2000]}\n",
    "\n",
    "colors = ['green', 'red', 'blue', 'orange', 'brown', 'grey']\n",
    "\n",
    "G = PlottingData(all_dfs, measures_to_plot, max_min, colors)\n",
    "\n",
    "G.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do:\n",
    "# check each time point\n",
    "# add absolute humidity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset analytics\n",
    "number and percent of missing data values (nans)\n",
    "percent of captured data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BS6': 4.722651554181693, 'BS5': 4.993673555461831, 'BS4': 5.2768021408262245, 'BS3': 5.055476766497039, 'BS2': 4.773703336636935, 'BS1': 30.87160108436704}\n"
     ]
    }
   ],
   "source": [
    "percent_nans = {}\n",
    "\n",
    "for df in all_dfs: \n",
    "    frame = all_dfs[df]\n",
    "    end = frame['time_hour'].tail(1)\n",
    "    perc = num_nans[df]/len(frame)\n",
    "    high = 100 * perc.max()\n",
    "    percent_nans[df] = high\n",
    "print(percent_nans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
