{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeOccupancy():\n",
    "    def __init__(self, path, freq = '60S'):\n",
    "        self.ground_path = os.path.join(path, 'GroundTruth')\n",
    "        self.write_dir = self.make_storage_directory(os.path.join(path, 'Full_Occupancy_Files'))\n",
    "        self.home = path.split('/')[-1].split('-')[-2]\n",
    "        self.system = path.split('/')[-1].split('-')[-1]\n",
    "        self.occ_freq = freq\n",
    "        self.occupant_names = []\n",
    "        \n",
    "\n",
    "    def mylistdir(self, directory):\n",
    "        filelist = os.listdir(directory)\n",
    "        return [x for x in filelist if x.endswith('.csv')]\n",
    "\n",
    "    def make_storage_directory(self, target_dir):\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "        return target_dir\n",
    "\n",
    "    def get_ground_truth(self):\n",
    "        occupant_files = self.mylistdir(self.ground_path)\n",
    "        occupants = {}\n",
    "        enter_times, exit_times = [], []\n",
    "        \n",
    "        for occ in occupant_files:\n",
    "            #occupant_name = occ.strip('.csv').split('-')[1] ## H3-black\n",
    "            occupant_name = occ.strip('.csv').split('-')[0]  ## H1, H3-red\n",
    "            self.occupant_names.append(occupant_name)\n",
    "            ishome = []\n",
    "            with open(os.path.join(self.ground_path, occ)) as csv_file:\n",
    "                csv_reader, line_count = csv.reader(csv_file, delimiter=','), 0\n",
    "                for row in csv_reader:\n",
    "                    status, when = row[1], row[2].split('at')\n",
    "                    dt_day = datetime.strptime(str(when[0] + when[1]), '%B %d, %Y  %I:%M%p')\n",
    "                    ishome.append((status, dt_day))\n",
    "                    if line_count == 0:\n",
    "                        enter_times.append(dt_day)\n",
    "                    line_count += 1\n",
    "                exit_times.append(dt_day)\n",
    "                \n",
    "            occupants[occupant_name] = ishome        \n",
    "        self.first_last = (sorted(enter_times)[0], sorted(exit_times)[-1])\n",
    "        return occupants\n",
    "    \n",
    "    def create_occupancy_df(self, occupants):\n",
    "        occ_range = pd.date_range(start=self.first_last[0], end=self.first_last[1], freq=self.occ_freq)    \n",
    "        occ_df = pd.DataFrame(index=occ_range)\n",
    "        \n",
    "        for occ in occupants:\n",
    "            occ_df[occ] = 99\n",
    "            s1 = 'exited'\n",
    "            for r in occupants[occ]:\n",
    "                date = r[1]\n",
    "                s2 = r[0]                \n",
    "                occ_df.loc[(occ_df.index < date) & (occ_df[occ]==99) & (s1 == 'exited') & (s2 == 'entered'), occ] =  0\n",
    "                occ_df.loc[(occ_df.index < date) & (occ_df[occ]==99) & (s1 == 'entered') & (s2 == 'exited'), occ] =  1\n",
    "                s1 = s2               \n",
    "            occ_df.loc[(occ_df.index >= date) & (occ_df[occ] == 99) & (s1 == 'entered'), occ] = 1\n",
    "            occ_df.loc[(occ_df.index >= date) & (occ_df[occ] == 99) & (s1 == 'exited'), occ] = 0    \n",
    "            \n",
    "        occ_df['number'] = occ_df[list(occupants.keys())].sum(axis = 1)\n",
    "        occ_df['occupied'] = 0\n",
    "        occ_df.loc[occ_df['number'] > 0, 'occupied'] = 1\n",
    "        return (occ_df)\n",
    "        \n",
    "    def write_occupancy_csv(self, df):       \n",
    "        fname = os.path.join(self.write_dir,'{}-Occupancy_df.csv'.format(self.home))\n",
    "        if not os.path.isfile(fname):\n",
    "            df.to_csv(fname, index = True)\n",
    "            print(fname + ': Write Sucessful!')\n",
    "        else:\n",
    "            print(fname + ': File already exists')    \n",
    "\n",
    "            \n",
    "    def main(self):\n",
    "        occupant_status = self.get_ground_truth()\n",
    "        self.df = self.create_occupancy_df(occupant_status)\n",
    "        self.write_occupancy_csv(self.df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H3/H3-red/Full_Occupancy_Files/H3-Occupancy_df.csv: Write Sucessful!\n",
      "                     Sophia  Martha  Maggie  Gregor  Josephine  Guests  \\\n",
      "2019-07-16 12:05:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:06:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:07:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:08:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:09:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:10:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:11:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:12:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:13:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:14:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:15:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:16:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:17:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:18:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:19:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:20:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:21:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:22:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:23:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:24:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:25:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:26:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:27:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:28:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:29:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:30:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:31:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:32:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:33:00       0       0       1       0          0       0   \n",
      "2019-07-16 12:34:00       0       0       1       0          0       0   \n",
      "...                     ...     ...     ...     ...        ...     ...   \n",
      "2019-09-06 17:11:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:12:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:13:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:14:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:15:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:16:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:17:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:18:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:19:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:20:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:21:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:22:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:23:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:24:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:25:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:26:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:27:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:28:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:29:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:30:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:31:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:32:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:33:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:34:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:35:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:36:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:37:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:38:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:39:00       0       1       0       1          0       0   \n",
      "2019-09-06 17:40:00       0       1       0       0          0       0   \n",
      "\n",
      "                     number  occupied  \n",
      "2019-07-16 12:05:00       1         1  \n",
      "2019-07-16 12:06:00       1         1  \n",
      "2019-07-16 12:07:00       1         1  \n",
      "2019-07-16 12:08:00       1         1  \n",
      "2019-07-16 12:09:00       1         1  \n",
      "2019-07-16 12:10:00       1         1  \n",
      "2019-07-16 12:11:00       1         1  \n",
      "2019-07-16 12:12:00       1         1  \n",
      "2019-07-16 12:13:00       1         1  \n",
      "2019-07-16 12:14:00       1         1  \n",
      "2019-07-16 12:15:00       1         1  \n",
      "2019-07-16 12:16:00       1         1  \n",
      "2019-07-16 12:17:00       1         1  \n",
      "2019-07-16 12:18:00       1         1  \n",
      "2019-07-16 12:19:00       1         1  \n",
      "2019-07-16 12:20:00       1         1  \n",
      "2019-07-16 12:21:00       1         1  \n",
      "2019-07-16 12:22:00       1         1  \n",
      "2019-07-16 12:23:00       1         1  \n",
      "2019-07-16 12:24:00       1         1  \n",
      "2019-07-16 12:25:00       1         1  \n",
      "2019-07-16 12:26:00       1         1  \n",
      "2019-07-16 12:27:00       1         1  \n",
      "2019-07-16 12:28:00       1         1  \n",
      "2019-07-16 12:29:00       1         1  \n",
      "2019-07-16 12:30:00       1         1  \n",
      "2019-07-16 12:31:00       1         1  \n",
      "2019-07-16 12:32:00       1         1  \n",
      "2019-07-16 12:33:00       1         1  \n",
      "2019-07-16 12:34:00       1         1  \n",
      "...                     ...       ...  \n",
      "2019-09-06 17:11:00       2         1  \n",
      "2019-09-06 17:12:00       2         1  \n",
      "2019-09-06 17:13:00       2         1  \n",
      "2019-09-06 17:14:00       2         1  \n",
      "2019-09-06 17:15:00       2         1  \n",
      "2019-09-06 17:16:00       2         1  \n",
      "2019-09-06 17:17:00       2         1  \n",
      "2019-09-06 17:18:00       2         1  \n",
      "2019-09-06 17:19:00       2         1  \n",
      "2019-09-06 17:20:00       2         1  \n",
      "2019-09-06 17:21:00       2         1  \n",
      "2019-09-06 17:22:00       2         1  \n",
      "2019-09-06 17:23:00       2         1  \n",
      "2019-09-06 17:24:00       2         1  \n",
      "2019-09-06 17:25:00       2         1  \n",
      "2019-09-06 17:26:00       2         1  \n",
      "2019-09-06 17:27:00       2         1  \n",
      "2019-09-06 17:28:00       2         1  \n",
      "2019-09-06 17:29:00       2         1  \n",
      "2019-09-06 17:30:00       2         1  \n",
      "2019-09-06 17:31:00       2         1  \n",
      "2019-09-06 17:32:00       2         1  \n",
      "2019-09-06 17:33:00       2         1  \n",
      "2019-09-06 17:34:00       2         1  \n",
      "2019-09-06 17:35:00       2         1  \n",
      "2019-09-06 17:36:00       2         1  \n",
      "2019-09-06 17:37:00       2         1  \n",
      "2019-09-06 17:38:00       2         1  \n",
      "2019-09-06 17:39:00       2         1  \n",
      "2019-09-06 17:40:00       1         1  \n",
      "\n",
      "[75216 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H3/H3-red'\n",
    "\n",
    "occ = HomeOccupancy(path)\n",
    "occ.main()\n",
    "print(occ.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
