{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomeData class\n",
    "This is the parent for the following four classes and gathers the home information (home number, color, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeData():\n",
    "    def __init__(self, path):\n",
    "        self.root_dir = path\n",
    "        self.write_dir = self.make_storage_directory(os.path.join(self.root_dir, 'Summaries'))\n",
    "        self.home = path.split('/')[-1].split('-')[-2]\n",
    "        #print(path.split('/'))\n",
    "        self.system = path.split('/')[-1].split('-')[-1]\n",
    "        self.average_length = 1\n",
    "    \n",
    "    def mylistdir(self, directory):\n",
    "        filelist = os.listdir(directory)\n",
    "        return [x for x in filelist if not (x.startswith('.') or 'Icon' in x)] \n",
    "\n",
    "    def make_storage_directory(self, target_dir):\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "        return target_dir\n",
    "    \n",
    "    def date_segments(self, dates):\n",
    "        output = []\n",
    "        cur_list = [dates[0]]\n",
    "        for dt_pair in zip(dates[1:], dates):\n",
    "            if (dt_pair[0] - dt_pair[1]).days > 1:\n",
    "                output.append(cur_list)\n",
    "                cur_list = [dt_pair[0]]\n",
    "            else:\n",
    "                cur_list.append(dt_pair[0])\n",
    "        output.append(cur_list)\n",
    "        return output   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomeOccupancy class\n",
    "This reads in the raw ground truth filese and creates the occupancy dataframes.\n",
    "Writes a summary df at the specified frequency.\n",
    "Stores in the ```Summary``` folder with the title structure ```H1-black-Occupancy_df.csv```\n",
    "\n",
    "eg:\n",
    "```\n",
    "path = '/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black'\n",
    "o = HomeOccupancy(path)\n",
    "o.main()\n",
    "o.df\n",
    "o.df.head()\n",
    "\n",
    "                     number  occupied\n",
    "2019-10-09 17:00:00       1         1\n",
    "2019-10-09 17:00:10       1         1\n",
    "2019-10-09 17:00:20       1         1\n",
    "2019-10-09 17:00:30       1         1\n",
    "2019-10-09 17:00:40       1         1\n",
    "2019-10-09 17:00:50       1         1\n",
    "2019-10-09 17:01:00       1         1\n",
    "2019-10-09 17:01:10       1         1\n",
    "2019-10-09 17:01:20       1         1\n",
    "2019-10-09 17:01:30       1         1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeOccupancy(HomeData):\n",
    "    \n",
    "    def __init__(self, path, freq = '10S'):      \n",
    "        HomeData.__init__(self, path) \n",
    "        self.ground_path = os.path.join(self.root_dir, 'GroundTruth')\n",
    "        self.occ_freq = freq    \n",
    "        self.occupant_names = []\n",
    "\n",
    "    def mylistdir(self, directory):\n",
    "        filelist = os.listdir(directory)\n",
    "        return [x for x in filelist if x.endswith('.csv')]        \n",
    "        \n",
    "    def get_ground_truth(self):\n",
    "        occupant_files = self.mylistdir(self.ground_path)\n",
    "        occupants = {}\n",
    "        enter_times, exit_times = [], []\n",
    "        \n",
    "        for occ in occupant_files:\n",
    "            occupant_name = occ.strip('.csv').split('-')[1] ## H3-black, H6-black\n",
    "            #occupant_name = occ.strip('.csv').split('-')[0]  ## H1, H3-red\n",
    "            self.occupant_names.append(occupant_name)\n",
    "            ishome = []\n",
    "            with open(os.path.join(self.ground_path, occ)) as csv_file:\n",
    "                csv_reader, line_count = csv.reader(csv_file, delimiter=','), 0\n",
    "                for row in csv_reader:\n",
    "                    status, when = row[1], row[2].split('at')\n",
    "                    dt_day = datetime.strptime(str(when[0] + when[1]), '%B %d, %Y  %I:%M%p')\n",
    "                    ishome.append((status, dt_day))\n",
    "                    if line_count == 0:\n",
    "                        enter_times.append(dt_day)\n",
    "                    line_count += 1\n",
    "                exit_times.append(dt_day)\n",
    "                \n",
    "            occupants[occupant_name] = ishome        \n",
    "        self.first_last = (sorted(enter_times)[0], sorted(exit_times)[-1])\n",
    "        return occupants\n",
    "    \n",
    "    def create_occupancy_df(self, occupants, frequency):\n",
    "        occ_range = pd.date_range(start=self.first_last[0], end=self.first_last[1], freq=frequency)    \n",
    "        occ_df = pd.DataFrame(index=occ_range)\n",
    "        \n",
    "        for occ in occupants:\n",
    "            occ_df[occ] = 99\n",
    "            s1 = 'exited'\n",
    "            for r in occupants[occ]:\n",
    "                date = r[1]\n",
    "                s2 = r[0]                \n",
    "                occ_df.loc[(occ_df.index < date) & (occ_df[occ]==99) & (s1 == 'exited') & (s2 == 'entered'), occ] =  0\n",
    "                occ_df.loc[(occ_df.index < date) & (occ_df[occ]==99) & (s1 == 'entered') & (s2 == 'exited'), occ] =  1\n",
    "                s1 = s2               \n",
    "            occ_df.loc[(occ_df.index >= date) & (occ_df[occ] == 99) & (s1 == 'entered'), occ] = 1\n",
    "            occ_df.loc[(occ_df.index >= date) & (occ_df[occ] == 99) & (s1 == 'exited'), occ] = 0    \n",
    "            \n",
    "        occ_df['number'] = occ_df[list(occupants.keys())].sum(axis = 1)\n",
    "        occ_df['occupied'] = 0\n",
    "        occ_df.loc[occ_df['number'] > 0, 'occupied'] = 1\n",
    "        return (occ_df)\n",
    "    \n",
    "    \n",
    "    def average_df(self, df):\n",
    "        time_series = []\n",
    "        for group, df_chunk in df.groupby(np.arange(len(df))//self.average_length):\n",
    "            df_max = df_chunk.max()\n",
    "            df_index = df_chunk.iloc[-1]\n",
    "            time_series.append(df_index.name)\n",
    "            df_summary = df_max.to_frame().transpose() \n",
    "            new_df = df_summary if group == 0 else pd.concat([new_df, df_summary])\n",
    "\n",
    "        new_df.index = time_series  \n",
    "        new_df = new_df[['number', 'occupied']]\n",
    "        return new_df\n",
    "\n",
    "    \n",
    "#     def not_average_df(self, df):\n",
    "#         time_series = []\n",
    "#         for group, df_chunk in df.groupby(np.arange(len(df))//self.average_length):\n",
    "#             df_max = df_chunk.max()\n",
    "#             df_index = df_chunk.iloc[-1]\n",
    "#             time_series.append(df_index.name)\n",
    "#             df_summary = df_max.to_frame().transpose() \n",
    "#             new_df = df_summary if group == 0 else pd.concat([new_df, df_summary])\n",
    "\n",
    "#         new_df.index = time_series  \n",
    "#         new_df = new_df[['number', 'occupied']]\n",
    "#         return new_df\n",
    "     \n",
    "       \n",
    "    def write_occupancy_csv(self, df, fname):       \n",
    "        fname = os.path.join(self.write_dir, fname)\n",
    "        if not os.path.isfile(fname):\n",
    "            df.to_csv(fname, index = True)\n",
    "            print(fname + ': Write Sucessful!')\n",
    "        else:\n",
    "            print(fname + ': File already exists')    \n",
    "\n",
    "            \n",
    "    def main(self):\n",
    "        occupant_status = self.get_ground_truth()\n",
    "        df = self.create_occupancy_df(occupant_status, frequency=self.occ_freq)\n",
    "        self.df = df[['number', 'occupied']]\n",
    "    \n",
    "\n",
    "        #self.df = self.average_df(df)        \n",
    "        #create larger grain for viewing (1 minute frequency)\n",
    "        write_df = self.create_occupancy_df(occupant_status, frequency='10S')\n",
    "        self.write_occupancy_csv(write_df, '{}-{}-Occupancy_df.csv'.format(self.home, self.system))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadEnv class\n",
    "This reads in all the env data from the json files and writes summaries of the data for each hub\n",
    "Summaries are text files for each hub, with and entry for each day  which gives the start/end time \n",
    "of the files, and the perecentage of minutes that have at least 1 entry\n",
    "\n",
    "File is stored under ```Summary``` folder with title structure ```H1-BS1-data-summary.txt```\n",
    "\n",
    "eg:\n",
    "```\n",
    "BS1 2019-02-19 (00:00, 23:59) 0.93\n",
    "BS1 2019-02-20 (00:00, 12:14) 0.50\n",
    "BS1 2019-02-22 (21:55, 22:24) 0.02\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadEnv(HomeData):\n",
    "    \n",
    "    def __init__(self, path, sensor_hub):\n",
    "        HomeData.__init__(self, path)\n",
    "        self.name = sensor_hub\n",
    "        self.env_dir = os.path.join(self.root_dir, self.name, 'env_params')\n",
    "        self.from_pi = os.path.join(self.root_dir, self.name, 'env_from_pi')\n",
    "        self.num_folders = 288\n",
    "        self.files_per = 5\n",
    "        self.minutes_per_day = 1440\n",
    "        self.all_data = {}\n",
    "        self.first_last = {}\n",
    "        self.total_minutes = {}\n",
    "        self.details = []\n",
    "\n",
    "        \n",
    "    def get_date_folders(self, path):\n",
    "        date_folders = self.mylistdir(path)\n",
    "        date_folders.sort()\n",
    "        self.day1, self.dayn = date_folders[0], date_folders[-1]\n",
    "        return date_folders\n",
    "\n",
    "    def read_in_data(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                self.data_dicts = json.loads(f.read())\n",
    "                for time_point in self.data_dicts:\n",
    "                    for measure in time_point:\n",
    "                        self.measurements[measure].append(time_point[measure])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def check_from_pi(self, path, day, b_f, min_n):\n",
    "        self.expected_jsons = pd.date_range(b_dt, e_dt, freq = '10S').tolist()\n",
    "        self.all_seconds = pd.date_range(b_f, e_f, freq = self.audio_tape_length + 'S').tolist()\n",
    "        self.expected_dirs = pd.date_range(b_dt, e_dt, freq = '60S').tolist()\n",
    "        #self.all_minutes = pd.date_range(b_f, e_f, freq = '60S').tolist()        \n",
    "            \n",
    "    \n",
    "    def get_all_data(self, path, day):\n",
    "        self.measurements = {\n",
    "            'time':[], 'tvoc_ppb':[], 'temp_c':[], 'rh_percent':[], \n",
    "            'light_lux':[],'co2eq_ppm':[], 'dist_mm':[], 'co2eq_base':[], 'tvoc_base':[]}\n",
    "        file_path = os.path.join(path, day)\n",
    "        minute_folders = self.mylistdir(file_path)\n",
    "        minute_folders.sort()\n",
    "#         mins_from_pi = self.mylistdir() #\n",
    "#         expected_jsons = \n",
    "        \n",
    "        \n",
    "        num_missing = 5 * (self.num_folders - len(minute_folders))\n",
    "        min_1, min_L = minute_folders[0], minute_folders[-1]\n",
    "        min_n = str(int(min_L) + 4).zfill(4)\n",
    "        self.first_last[day] = min_1, min_n\n",
    "        \n",
    "        \n",
    "        for minute in minute_folders:\n",
    "            sub_files_path = os.path.join(file_path, minute)\n",
    "            sub_files = self.mylistdir(sub_files_path)\n",
    "            sub_files.sort()\n",
    "            missing = self.files_per - len(sub_files)\n",
    "            num_missing += missing\n",
    "            for file in sub_files:\n",
    "                if file.endswith('.json'):\n",
    "                    self.read_in_data(os.path.join(sub_files_path, file))\n",
    "        \n",
    "        self.all_data[day] = self.measurements\n",
    "        total_day = 1440 - num_missing\n",
    "        self.total_minutes[day] = total_day\n",
    "        \n",
    "    \n",
    "    def get_day_summary(self, day):\n",
    "        self.get_all_data(self.env_dir, day)\n",
    "        try:\n",
    "            total = self.total_minutes[day]/self.minutes_per_day\n",
    "            perc = '{:.2f}'.format(total)\n",
    "        except Exception as e:\n",
    "            print('except: {}'.format(e))\n",
    "            perc = 0.00\n",
    "        F1, F2 = self.first_last[day][0], self.first_last[day][1]\n",
    "        s = (f'({F1[0:2]}:{F1[2:4]}, {F2[0:2]}:{F2[2:4]})')\n",
    "        details = '{} {} {} {}'.format(self.name, day, s, perc)\n",
    "        return details, total\n",
    "\n",
    "      \n",
    "    def get_date_splits(self, dates):\n",
    "        dt_dates = [datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "        date_lists = self.date_segments(dt_dates)\n",
    "        all_lists = [[date.strftime('%Y-%m-%d') for date in sublist] for sublist in date_lists]\n",
    "        return all_lists\n",
    "    \n",
    "    \n",
    "    def read_all_days(self):\n",
    "        dates_to_use = []\n",
    "        date_folders = self.get_date_folders(self.env_dir)\n",
    "        fname = os.path.join(self.write_dir, '{}-{}-data-summary.txt'.format(self.home, self.name))\n",
    "        with open(fname, 'w+') as writer:\n",
    "            for day in date_folders:\n",
    "                day_details, total = self.get_day_summary(day)\n",
    "                #print(day_details)\n",
    "                writer.write(day_details + '\\n')\n",
    "                self.details.append(day_details)\n",
    "                if total > 0.85:\n",
    "                    dates_to_use.append(day)               \n",
    "            self.lists_of_dates = self.get_date_splits(dates_to_use)    \n",
    "        writer.close()\n",
    "        print(fname + ': Write Sucessful!')\n",
    "    \n",
    "   \n",
    "    def main(self):\n",
    "        self.read_all_days()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CleanEnvData class\n",
    "This performs the heavy lifting of processing the env params that have preeviously been read in and saved as a df.\n",
    "This also writes csvs to four different folder locations:\n",
    "\n",
    "Under the ```Complete_CSV``` folder it creates a csv for each day and each hub\n",
    "Under the ```Stacked_CSV``` folder it creates a csv for multiple days stacked together \n",
    "Under the ```Stacked_CSV_10sec``` folder it creates the same as above, but with occupancy attached\n",
    "Under the ```Stacked_CSV_5min``` folder it creates the same as above (with occupancy attached), but averaged over 5 minute periods. This frequency can be changed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanEnvData(HomeData):\n",
    "    \n",
    "    def __init__(self, path, lists, data, hubs, occ):\n",
    "        HomeData.__init__(self, path)\n",
    "        self.all_data = data\n",
    "        self.dates_in_common = lists\n",
    "        self.sensor_hubs = hubs\n",
    "        self.occupancy_df = occ\n",
    "        self.all_dfs = {}\n",
    "        self.var_names1 = ['tvoc_ppb', 'temp_c', 'rh_percent', 'light_lux', 'co2eq_ppm', 'dist_mm', 'abs_humid']\n",
    "        self.var_names2 = ['home', 'sensor']\n",
    "        \n",
    "    def csv_name(self, name, day):       \n",
    "        return str(self.home + '_' + name + '_' + day + '.csv')     \n",
    "        \n",
    "    def create_full_dfs(self, df, D1):\n",
    "        df_fullday = self.make_date_range(day1 = D1) ##use this for full 24hours\n",
    "        df2 = df.reindex(df_fullday, fill_value = np.nan) \n",
    "        df2.fillna(np.nan)\n",
    "        return df2\n",
    "        \n",
    "        \n",
    "    def make_date_range(self, day1, dayn=None, t1 = '0000', tn = '2359'):\n",
    "        self.range_start = str(day1 + ' ' + t1[0:2] + ':' + t1[2:4] + ':00')\n",
    "        self.range_end = str(day1 + ' ' + tn[0:2] + ':' + tn[2:4] + ':50')\n",
    "        date_range = pd.date_range(start=self.range_start, end=self.range_end, freq='10s')\n",
    "        return date_range \n",
    "        \n",
    "        \n",
    "    def clean_dates(self, name, day, df): \n",
    "        df['time'] = df['time'].str.strip('Z').str.replace('T',' ')\n",
    "        df['datetime_index'] = pd.to_datetime(df['time'])         \n",
    "        df = df.set_index('datetime_index')\n",
    "        df.index = df.index.floor('10s')\n",
    "        df2 = self.create_full_dfs(df, day)        \n",
    "        str_date = df2.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        df2.insert(loc = 0, column = 'str_datetime', value = str_date)\n",
    "        datetime_col = df2['str_datetime'].str.split(' ', n = 1, expand = True)         \n",
    "        df2.insert(loc = 0, column = 'date', value = datetime_col[0])\n",
    "        df2.insert(loc = 0, column = 'time-hr-min-sec', value = datetime_col[1])\n",
    "        time_col = datetime_col[1].str.split(':', n = 2, expand = True)    \n",
    "        df2.insert(loc = 0, column = 'second', value = time_col[2])\n",
    "        df2.insert(loc = 0, column = 'minute', value = time_col[1])\n",
    "        df2.insert(loc = 0, column = 'hour', value = time_col[0])        \n",
    "        df2 = df2.drop(columns = ['str_datetime', 'time'])\n",
    "        df2 = df2.sort_values(by = ['date', 'hour', 'minute', 'second'])\n",
    "        df2['home'] = self.home\n",
    "        df2['sensor'] = name\n",
    "        #df2 = df2.drop(columns = ['hour', 'minute', 'second', 'time-hr-min-sec', 'date'])\n",
    "\n",
    "        return df2     \n",
    "    \n",
    "    \n",
    "    def absolute_humidity(self, df):\n",
    "        df['abs_humid'] = 13.247*df['rh_percent']*(2.718281828459045**((17.67*df['temp_c'])/(243.5+df['temp_c']))/(273.15+df['temp_c']))\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def check_rh(self, df, day, limit=3000):\n",
    "        big_rh = df.loc[df.rh_percent > limit]\n",
    "        if len(big_rh) > 0:\n",
    "            print(big_rh)\n",
    "        else:\n",
    "            print('No high value rh for day {}'.format(day))\n",
    "        df.loc[df.rh_percent > limit, 'rh_percent'] = np.nan\n",
    "        return df \n",
    "    \n",
    "    \n",
    "    def make_single_dfs(self):\n",
    "        for sensor_hub in self.sensor_hubs:\n",
    "            for date_list in self.dates_in_common:\n",
    "                #day1, dayn = date_list[0], date_list[-1]\n",
    "                for day in date_list:\n",
    "                    new_df = pd.DataFrame.from_dict(self.all_data[sensor_hub][day])\n",
    "                    new_df = self.absolute_humidity(new_df)\n",
    "                    new_df = self.check_rh(new_df, day)  \n",
    "                    clean_df = self.clean_dates(sensor_hub, day, new_df)\n",
    "                    self.write_data(sensor_hub, day, clean_df)\n",
    "    \n",
    "    \n",
    "    def write_data(self, hub, df_to_write, folder, title):\n",
    "        storage_path = self.make_storage_directory(os.path.join(self.root_dir, hub, folder))\n",
    "        target_fname = os.path.join(storage_path, self.csv_name(hub, title)) \n",
    "        if not os.path.isfile(target_fname):\n",
    "            df_to_write.to_csv(target_fname, index_label = 'timestamp', index = True)\n",
    "            print(target_fname + ': Write Sucessful!')\n",
    "        else:\n",
    "            print(target_fname + ': File already exists')    \n",
    "            \n",
    "    \n",
    "    def join_dfs(self, date_list, sensor_hub):\n",
    "        df_list = []\n",
    "        for day in date_list:\n",
    "            new_df = pd.DataFrame.from_dict(self.all_data[sensor_hub][day])\n",
    "            new_df = self.absolute_humidity(new_df)\n",
    "            new_df = self.check_rh(new_df, day)  \n",
    "            clean_df = self.clean_dates(sensor_hub, day, new_df)\n",
    "            self.write_data(hub=sensor_hub, df_to_write=clean_df, folder='Complete_CSV', title = day)\n",
    "            df_list.append(clean_df)\n",
    "            \n",
    "        full_df = pd.concat(df_list)\n",
    "        full_df = full_df.ffill(limit = 30)\n",
    "        full_df = full_df.bfill(limit = 30) \n",
    "        full_df = full_df.drop(columns = ['hour', 'minute', 'second', 'time-hr-min-sec', 'date'])\n",
    "        \n",
    "        return full_df\n",
    "    \n",
    "    \n",
    "    def average_dfs(self, df):\n",
    "        time_series = []\n",
    "        \n",
    "        for group, df_chunk in df.groupby(np.arange(len(df))//self.average_length):\n",
    "            df_means = df_chunk[self.var_names1].mean()\n",
    "            df_index = df_chunk.iloc[-1][self.var_names2]\n",
    "            time_series.append(df_index.name)\n",
    "            sr_summary = df_index.append(df_means, ignore_index = False)\n",
    "            df_summary = sr_summary.to_frame().transpose()   \n",
    "            new_df = df_summary if group == 0 else pd.concat([new_df, df_summary])\n",
    "        \n",
    "        new_df.index = time_series\n",
    "        \n",
    "        return new_df\n",
    "    \n",
    "     \n",
    "    def attach_occupancy(self, df):\n",
    "        joined_df = pd.concat([df, self.occupancy_df], axis=1, join='inner')\n",
    "        return joined_df\n",
    "\n",
    "        \n",
    "        \n",
    "    def main(self): \n",
    "        for sensor_hub in self.sensor_hubs:\n",
    "            sensor_full_dfs = []\n",
    "            for date_list in self.dates_in_common:\n",
    "                day1, dayn = date_list[0], date_list[-1]\n",
    "                \n",
    "                full_df = self.join_dfs(date_list, sensor_hub)\n",
    "                self.write_data(hub=sensor_hub, df_to_write=full_df, folder='Stacked_CSV', title='{}_to_{}'.format(day1, dayn)) \n",
    "                \n",
    "                full_with_occ = self.attach_occupancy(full_df)\n",
    "                full_with_occ = full_with_occ.drop(columns = ['co2eq_base', 'tvoc_base'])\n",
    "                self.write_data(hub=sensor_hub, df_to_write=full_with_occ, folder='Stacked_CSV_10sec', title='{}_to_{}-occ'.format(day1, dayn)) \n",
    "#                 print(full_with_occ.columns)\n",
    "\n",
    "                averaged_df = self.average_dfs(full_df)\n",
    "#                 cols = averaged_df.columns.tolist()\n",
    "#                 cols = cols[2:] + cols[:2]\n",
    "#                 averaged_df = averaged_df[cols]               \n",
    "                df_w_occ = self.attach_occupancy(averaged_df)\n",
    "                self.write_data(hub=sensor_hub, df_to_write=df_w_occ, folder='Stacked_CSV_5min', title='{}_to_{}-averaged-occ'.format(day1, dayn))    \n",
    "\n",
    "                \n",
    "                #sensor_full_dfs.append(df_w_occ)               \n",
    "            self.all_dfs[sensor_hub] = sensor_full_dfs\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RS1']\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/maggie/Desktop/HPD_mobile_data/HPD-env-summaries/HPD_mobile-H1/H1-red'\n",
    "sensors_red = ['RS1']#, 'RS2', 'RS3', 'RS4', 'RS5']\n",
    "sensors_black = ['BS2', 'BS3', 'BS4', 'BS5']\n",
    "\n",
    "\n",
    "R_set = [('r{}'.format(x), 'RS{}'.format(x)) for x in np.arange(1,6)]\n",
    "B_set = [('b{}'.format(x), 'BS{}'.format(x)) for x in np.arange(1,7)]\n",
    "\n",
    "print(sensors_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BS2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1fbdc675326a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m Lists = [(tuple(b2), tuple(b3), tuple(b4), tuple(b5)) \n\u001b[0;32m---> 23\u001b[0;31m          \u001b[0;32mfor\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dates_to_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BS2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mb3\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dates_to_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BS3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m          \u001b[0;32mfor\u001b[0m \u001b[0mb4\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_dates_to_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BS4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BS2'"
     ]
    }
   ],
   "source": [
    "# o = HomeOccupancy(path)\n",
    "# o.main()\n",
    "\n",
    "# all_sensor_data = {}\n",
    "# all_dates_to_use = {}\n",
    "# all_details = {}\n",
    "\n",
    "# for sensor in sensors_black:\n",
    "#     s = ReadEnv(path, sensor)\n",
    "#     s.main()\n",
    "#     all_sensor_data[sensor] = s.all_data\n",
    "#     all_dates_to_use[sensor] = s.lists_of_dates\n",
    "# #     all_details[sensor] = s.details\n",
    "\n",
    "# # Lists = [(tuple(r1), tuple(r2), tuple(r3), tuple(r4), tuple(r5)) \n",
    "# #          for r1 in all_dates_to_use['RS1']\n",
    "# #          for r2 in all_dates_to_use['RS2']\n",
    "# #          for r3 in all_dates_to_use['RS3']\n",
    "# #          for r4 in all_dates_to_use['RS4']\n",
    "# #          for r5 in all_dates_to_use['RS5']]   \n",
    "\n",
    "Lists = [(tuple(b2), tuple(b3), tuple(b4), tuple(b5)) \n",
    "         for b2 in all_dates_to_use['BS2']\n",
    "         for b3 in all_dates_to_use['BS3']\n",
    "         for b4 in all_dates_to_use['BS4']\n",
    "         for b5 in all_dates_to_use['BS5']]    \n",
    "  \n",
    "        \n",
    "same_dates = []\n",
    "for L in Lists:\n",
    "    same_lists = set(L[0]).intersection(*L)\n",
    "    if len(same_lists) > 0:\n",
    "        same_dates.append(sorted(same_lists))\n",
    "\n",
    "print('\\n\\n*** There are {} lists ***\\n'.format(len(same_dates)))\n",
    "for l in same_dates:\n",
    "    print(l) \n",
    "\n",
    "\n",
    "\n",
    "e = CleanEnvData(path, same_dates, all_sensor_data, sensors_black, o.df)\n",
    "e.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/Summaries/H6-black-Occupancy_df.csv: Write Sucessful!\n"
     ]
    }
   ],
   "source": [
    "o = HomeOccupancy(path)\n",
    "o.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>occupied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:00:50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:01:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:01:10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:01:20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09 17:01:30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number  occupied\n",
       "2019-10-09 17:00:00       1         1\n",
       "2019-10-09 17:00:10       1         1\n",
       "2019-10-09 17:00:20       1         1\n",
       "2019-10-09 17:00:30       1         1\n",
       "2019-10-09 17:00:40       1         1\n",
       "2019-10-09 17:00:50       1         1\n",
       "2019-10-09 17:01:00       1         1\n",
       "2019-10-09 17:01:10       1         1\n",
       "2019-10-09 17:01:20       1         1\n",
       "2019-10-09 17:01:30       1         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggie/Desktop/HPD_mobile_data/HPD-env-summaries/HPD_mobile-H1/H1-red/RS1/env_params\n",
      "except: '2019-11-05'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'2019-11-05'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c6837bdc2dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensors_red\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mall_sensor_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mall_dates_to_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlists_of_dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-81a95c9ac485>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_all_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-81a95c9ac485>\u001b[0m in \u001b[0;36mread_all_days\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdate_folders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mday_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_day_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;31m#print(day_details)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_details\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-81a95c9ac485>\u001b[0m in \u001b[0;36mget_day_summary\u001b[0;34m(self, day)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'except: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mperc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mF1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_last\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_last\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'({F1[0:2]}:{F1[2:4]}, {F2[0:2]}:{F2[2:4]})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} {} {} {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2019-11-05'"
     ]
    }
   ],
   "source": [
    "all_sensor_data = {}\n",
    "all_dates_to_use = {}\n",
    "all_details = {}\n",
    "\n",
    "for sensor in sensors_red:\n",
    "    s = ReadEnv(path, sensor)\n",
    "    s.main()\n",
    "    all_sensor_data[sensor] = s.all_data\n",
    "    all_dates_to_use[sensor] = s.lists_of_dates\n",
    "#     all_details[sensor] = s.details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor BS2 list 1 has 11 dates\n",
      "['2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20']\n",
      "\n",
      "Sensor BS2 list 2 has 42 dates\n",
      "['2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02']\n",
      "\n",
      "Sensor BS2 list 3 has 7 dates\n",
      "['2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10']\n",
      "\n",
      "Sensor BS3 list 1 has 16 dates\n",
      "['2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25']\n",
      "\n",
      "Sensor BS3 list 2 has 43 dates\n",
      "['2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10']\n",
      "\n",
      "Sensor BS4 list 1 has 46 dates\n",
      "['2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24']\n",
      "\n",
      "Sensor BS4 list 2 has 15 dates\n",
      "['2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10']\n",
      "\n",
      "Sensor BS5 list 1 has 1 dates\n",
      "['2019-10-10']\n",
      "\n",
      "Sensor BS5 list 2 has 27 dates\n",
      "['2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07']\n",
      "\n",
      "Sensor BS5 list 3 has 2 dates\n",
      "['2019-11-09', '2019-11-10']\n",
      "\n",
      "Sensor BS5 list 4 has 17 dates\n",
      "['2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28']\n",
      "\n",
      "Sensor BS5 list 5 has 11 dates\n",
      "['2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10']\n",
      "\n",
      "\n",
      "*** There are 9 lists ***\n",
      "\n",
      "['2019-10-10']\n",
      "['2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20']\n",
      "['2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25']\n",
      "['2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07']\n",
      "['2019-11-09', '2019-11-10']\n",
      "['2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24']\n",
      "['2019-11-26', '2019-11-27', '2019-11-28']\n",
      "['2019-11-30', '2019-12-01', '2019-12-02']\n",
      "['2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10']\n"
     ]
    }
   ],
   "source": [
    "# Lists = [(tuple(r1), tuple(r2), tuple(r3), tuple(r4), tuple(r5)) \n",
    "#          for r1 in all_dates_to_use['RS1']\n",
    "#          for r2 in all_dates_to_use['RS2']\n",
    "#          for r3 in all_dates_to_use['RS3']\n",
    "#          for r4 in all_dates_to_use['RS4']\n",
    "#          for r5 in all_dates_to_use['RS5']]   \n",
    "  \n",
    "    \n",
    "    \n",
    "# Lists = [(tuple(r2), tuple(r3), tuple(r4), tuple(r5)) \n",
    "#          for r2 in all_dates_to_use['RS2']\n",
    "#          for r3 in all_dates_to_use['RS3']\n",
    "#          for r4 in all_dates_to_use['RS4']\n",
    "#          for r5 in all_dates_to_use['RS5']]   \n",
    "\n",
    "# Lists = [(tuple(b1), tuple(b2), tuple(b3), tuple(b4), tuple(b5), tuple(b6)) \n",
    "#          for b1 in all_dates_to_use['BS1']\n",
    "#          for b2 in all_dates_to_use['BS2']\n",
    "#          for b3 in all_dates_to_use['BS3']\n",
    "#          for b4 in all_dates_to_use['BS4']\n",
    "#          for b5 in all_dates_to_use['BS5']\n",
    "#          for b6 in all_dates_to_use['BS6']]    \n",
    "\n",
    "Lists = [(tuple(b2), tuple(b3), tuple(b4), tuple(b5)) \n",
    "         for b2 in all_dates_to_use['BS2']\n",
    "         for b3 in all_dates_to_use['BS3']\n",
    "         for b4 in all_dates_to_use['BS4']\n",
    "         for b5 in all_dates_to_use['BS5']]  \n",
    "\n",
    "for s in all_dates_to_use:\n",
    "    for i, l in enumerate(all_dates_to_use[s]):\n",
    "        print('\\nSensor {} list {} has {} dates'.format(s, i+1, len(l)))\n",
    "        print(l)    \n",
    "        \n",
    "same_dates = []\n",
    "for L in Lists:\n",
    "    same_lists = set(L[0]).intersection(*L)\n",
    "    if len(same_lists) > 0:\n",
    "        same_dates.append(sorted(same_lists))\n",
    "\n",
    "print('\\n\\n*** There are {} lists ***\\n'.format(len(same_dates)))\n",
    "for l in same_dates:\n",
    "    print(l) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RS1', 'RS2', 'RS3', 'RS4', 'RS5']\n",
      "['RS2', 'RS3', 'RS4', 'RS5']\n",
      "[['2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20']]\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-10-10_to_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-10-10_to_2019-10-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-10-10_to_2019-10-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-10-12_to_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-10-12_to_2019-10-20-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-10-12_to_2019-10-20-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-10-22_to_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-10-22_to_2019-10-25-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-10-22_to_2019-10-25-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-29.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-10-31.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-03.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-10-29_to_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-10-29_to_2019-11-07-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-10-29_to_2019-11-07-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-11-09_to_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-11-09_to_2019-11-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-11-09_to_2019-11-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-21.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-11-12_to_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-11-12_to_2019-11-24-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-11-12_to_2019-11-24-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-26.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-27.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-11-26_to_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-11-26_to_2019-11-28-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-11-26_to_2019-11-28-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-11-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-11-30_to_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-11-30_to_2019-12-02-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-11-30_to_2019-12-02-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-08.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Complete_CSV/H6_BS2_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV/H6_BS2_2019-12-04_to_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_10sec/H6_BS2_2019-12-04_to_2019-12-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS2/Stacked_CSV_5min/H6_BS2_2019-12-04_to_2019-12-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-10-10_to_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-10-10_to_2019-10-10-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-10-10_to_2019-10-10-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-10-12_to_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-10-12_to_2019-10-20-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-10-12_to_2019-10-20-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-10-22_to_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-10-22_to_2019-10-25-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-10-22_to_2019-10-25-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-29.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-10-31.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-03.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-10-29_to_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-10-29_to_2019-11-07-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-10-29_to_2019-11-07-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-11-09_to_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-11-09_to_2019-11-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-11-09_to_2019-11-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-21.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-11-12_to_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-11-12_to_2019-11-24-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-11-12_to_2019-11-24-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-26.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-27.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-11-26_to_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-11-26_to_2019-11-28-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-11-26_to_2019-11-28-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-11-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-11-30_to_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-11-30_to_2019-12-02-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-11-30_to_2019-12-02-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-08.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Complete_CSV/H6_BS3_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV/H6_BS3_2019-12-04_to_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_10sec/H6_BS3_2019-12-04_to_2019-12-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS3/Stacked_CSV_5min/H6_BS3_2019-12-04_to_2019-12-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-10-10_to_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-10-10_to_2019-10-10-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-10-10_to_2019-10-10-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-10-12_to_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-10-12_to_2019-10-20-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-10-12_to_2019-10-20-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-10-22_to_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-10-22_to_2019-10-25-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-10-22_to_2019-10-25-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-29.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-10-31.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-03.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-10-29_to_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-10-29_to_2019-11-07-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-10-29_to_2019-11-07-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-11-09_to_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-11-09_to_2019-11-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-11-09_to_2019-11-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-21.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-11-12_to_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-11-12_to_2019-11-24-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-11-12_to_2019-11-24-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-26.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-27.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-11-26_to_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-11-26_to_2019-11-28-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-11-26_to_2019-11-28-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-11-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-11-30_to_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-11-30_to_2019-12-02-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-11-30_to_2019-12-02-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-08.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Complete_CSV/H6_BS4_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV/H6_BS4_2019-12-04_to_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_10sec/H6_BS4_2019-12-04_to_2019-12-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS4/Stacked_CSV_5min/H6_BS4_2019-12-04_to_2019-12-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-10-10_to_2019-10-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-10-10_to_2019-10-10-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-10-10_to_2019-10-10-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-10-12_to_2019-10-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-10-12_to_2019-10-20-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-10-12_to_2019-10-20-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-10-22_to_2019-10-25.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-10-22_to_2019-10-25-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-10-22_to_2019-10-25-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-29.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-10-31.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-03.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-10-29_to_2019-11-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-10-29_to_2019-11-07-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-10-29_to_2019-11-07-averaged-occ.csv: Write Sucessful!\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-11-09_to_2019-11-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-11-09_to_2019-11-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-11-09_to_2019-11-10-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-12.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-13.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-14.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-15.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-16.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-17.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-18.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-19.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-20.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-21.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-22.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-23.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-11-12_to_2019-11-24.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-11-12_to_2019-11-24-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-11-12_to_2019-11-24-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-26.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-27.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-11-26_to_2019-11-28.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-11-26_to_2019-11-28-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-11-26_to_2019-11-28-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-11-30.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-01.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-11-30_to_2019-12-02.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-11-30_to_2019-12-02-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-11-30_to_2019-12-02-averaged-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-04.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-05.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-06.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-07.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-08.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-09.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Complete_CSV/H6_BS5_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV/H6_BS5_2019-12-04_to_2019-12-10.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_10sec/H6_BS5_2019-12-04_to_2019-12-10-occ.csv: File already exists\n",
      "/Users/maggie/Desktop/HPD_mobile_data/HPD_mobile-H6/H6-black/BS5/Stacked_CSV_5min/H6_BS5_2019-12-04_to_2019-12-10-averaged-occ.csv: File already exists\n"
     ]
    }
   ],
   "source": [
    "dates = [same_dates[1]]\n",
    "sensors = sensors_red[1:]\n",
    "print(sensors_red)\n",
    "print(sensors)\n",
    "print(dates)\n",
    "\n",
    "e = CleanEnvData(path, same_dates, all_sensor_data, sensors_black, o.df)\n",
    "\n",
    "\n",
    "#e = CleanEnvData(path, same_dates, all_sensor_data, sensors_black, o.df)\n",
    "\n",
    "e.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RS1', 'RS2', 'RS3', 'RS4', 'RS5']\n",
      "['RS2', 'RS3', 'RS4', 'RS5']\n"
     ]
    }
   ],
   "source": [
    "sensors = sensors_red[1:]\n",
    "print(sensors_red)\n",
    "print(sensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
